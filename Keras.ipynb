{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Doit_Keras.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPLt3TcCI7TDD/4ETZCw82v"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Keras: 케라스**\n","\n","케라스는 딥러닝 패키지를 편리하게 사용하기 위해 만들어진 래퍼(wrapper)이다.   \n","대표적인 딥러닝 패키지인 텐서플로, 씨아노 등을 사용해 신경망을 구현하려면 많은 양의 코드가 필요하다.   "],"metadata":{"id":"K7GqTykVXITS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Acr7PG-FXE8e"},"outputs":[],"source":["!pip install tensorflow_gpu==2.0.0"]},{"cell_type":"code","source":["import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","(train_data_all, train_target_all), (test_data, test_target) = tf.keras.datasets.fashion_mnist.load_data()\n","train_data, val_data, train_target, val_target = train_test_split(train_data_all, train_target_all, stratify=train_target_all, test_size=0.2, random_state=42)\n","train_data = train_data / 255\n","val_data = val_data / 255\n","train_data = train_data.reshape(-1, 784)\n","val_data = val_data.reshape(-1, 784)\n","train_target_encoded = tf.keras.utils.to_categorical(train_target)\n","val_target_encoded = tf.keras.utils.to_categorical(val_target)"],"metadata":{"id":"FScH-eBLpgCk","executionInfo":{"status":"ok","timestamp":1651761775664,"user_tz":-540,"elapsed":1234,"user":{"displayName":"정환희","userId":"10718546972386594771"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["#**Keras's Class**\n","\n","케라스는 인공신경망을 '직관적으로' 구현할 수 있다.   \n","케라스에는 신경망 모델을 만드는 Sequential 클래스와 연결층을 만드는 Dense 클래스가 있다."],"metadata":{"id":"AI6pyrUnYZWL"}},{"cell_type":"markdown","source":["#**Sequential Class**\n","\n","완전 연결(fully-connected) 신경망을 만들기 위해서는 Sequential과 Dense 클래스를 함께 사용한다.   \n","Sequential 객체를 생성할 때 층을 추가하는 방법과, 객체 생성 후 add() 메서드를 사용해 층을 추가하는 방법이 있다."],"metadata":{"id":"3TugqjDUZTnq"}},{"cell_type":"code","source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Dense\n","model = Sequential([Dense(...), ...]) # Sequential 객체 생성 시 연결층 추가하는 방법"],"metadata":{"id":"l8HxwXpoX_q6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dense = Dense(...)\n","model.add(dense)    # 객체 생성 뒤 add()로 층 추가하기"],"metadata":{"id":"onAq1wd8Z80U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Sequential()\n","model.add(Dense(...)) # add()로 추가할 때 Dense 클래스 만들기"],"metadata":{"id":"S7cEJ-mZaktn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Dense Class**\n","\n","Dense 클래스에 전달해야 하는 첫 파라미터는 층의 **유닛(unit)**이다.   \n","은닉층의 유닛 개수를 100으로 지정하는 것으로 하자.\n","\n","그 다음 전달해야 하는 파라미터는 활성화 함수 **activation**이다.   \n","activation을 따로 입력하지 않으면 기본값은 None으로 활성화 함수가 적용되지 않는다.   \n","activation에는 'sigmoid', 'softmax', 'tanh', 'relu' 등이 있다."],"metadata":{"id":"AUz0bHeIbBVJ"}},{"cell_type":"code","source":["Dense(100, activation='sigmoid')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f5oUWZKbn73","executionInfo":{"status":"ok","timestamp":1651757730872,"user_tz":-540,"elapsed":17,"user":{"displayName":"정환희","userId":"10718546972386594771"}},"outputId":"7263de28-ca35-40a0-c548-9f00964dc223"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.layers.core.Dense at 0x7f6766037990>"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["#**Optimizer & Loss**\n","\n","모델을 훈련하기 위해서는 최적화 알고리즘이나 손실함수를 지정해야 한다.   \n","다중 분류에서의 최적화 알고리즘은 경사하강법, 손실함수는 크로스 엔트로피 손실함수를 사용한다.   \n","\n","\n","##**Optimizer: 최적화 알고리즘**\n","Sequential 클래스의 compile() 메서드를 사용해 최적화 알고리즘과 손실함수를 지정한다.   \n","optimizer 파라미터로 최적화 알고리즘을 지정한다.   \n","'sgd'를 입력하면 기본 경사 하강법을 최적화 알고리즘으로 사용한다.(이때 학습률의 기본값은 0.01이다.)"],"metadata":{"id":"fgVU6kOlcHhG"}},{"cell_type":"code","source":["model.compile(optimizer='sgd', ...)"],"metadata":{"id":"l57N4c5Tbsf1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Loss: 손실함수**\n","\n","loss 파라미터를 사용해 손실함수를 지정한다.   \n","지금까지 공부한 손실함수는 제곱오차, 로지스틱, 크로스 엔트로피가 있다.   \n","'mse'는 제곱오차, 'binary_crossentropy'는 로지스틱, 'categorical_crossentropy'는 크로스 엔트로피이다.   \n","지금은 다중 분류 신경망을 구현할 것이므로 categorical_crossentropy로 지정한다."],"metadata":{"id":"0GYc2yHFeQ7W"}},{"cell_type":"code","source":["model.compile(optimizer='sgd', loss='categorical_crossentropy')"],"metadata":{"id":"IDcs3pLMe8Wp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**모델 훈련 및 예측**\n","\n","Sequential 클래스의 fit() 메서드를 통해 훈련하고,   \n","predict() 메서드를 통해 예측한다.   \n","모델을 테스트 세트나 검증세트에서 평가할 때에는 evaluate() 메서드를 사용한다."],"metadata":{"id":"ik3fKvqpfHQV"}},{"cell_type":"code","source":["model = Sequential()  # 객체 생성\n","model.add(Dense(...)) # 연결층 추가\n","model.add(Dense(...))\n","model.compile(optimizer='...', loss='...')  # 최적화 알고리즘 및 손실함수 지정\n","model.fit(x, y, epochs=...) # 훈련\n","model.predict(x)  # 예측\n","model.evaluate(x, y)  # 평가"],"metadata":{"id":"yeV-97DOfY3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#**Keras로 다중 분류 신경망을 만들어보자**\n","케라스를 이용해 다중 분류 신경망을 만든 다음 패션 MNIST 데이터셋을 이용해 훈련시켜보자.\n","\n","1. Sequential()로 객체를 생성한 다음 Dense() 연결층을 추가해주자.   \n","\n","2. 이때 앞에서 MultiClassNetwork 클래스에서는 100개의 은닉층과 10개의 출력층이 있었으므로, Dense에 각각 100, 10을 넣어주자.   \n","또한 은닉층의 활성화 함수는 시그모이드, 출력층의 활성화 함수는 소프트맥스 였으므로 각각 맞게 입력해주자.\n","\n","3. 여기서 은닉층에는 input_shape 파라미터로 입력 데이터의 크기를 지정해야 한다.   \n","앞에서 28x28 사이즈의 이미지를 reshape 하여 (784,) 사이즈로 만들었기 때문에   \n","input_shape=(784, )를 입력해주자.\n","\n","4. compile 메서드에 optimizer와 loss를 각각 sgd, categorical_crossentropy로 지정하자.\n","여기서 matrics 파라미터는 훈련 과정 기록으로 '정확도'를 남기기 위해 추가한다.   \n","matrics를 지정하지 않으면 History 객체에 기본값으로 손실값이 기록되지만   \n","'accuracy'를 넣어주어 정확도를 기록하도록 했다.\n","\n","\n"],"metadata":{"id":"2nqldmX4f1Ob"}},{"cell_type":"code","source":["model = Sequential()  # 객체 생성하기\n","model.add(Dense(100, activation='sigmoid', input_shape=(784, ))) # 은닉층 추가\n","model.add(Dense(10, activation='softmax'))  # 출력층 추가\n","model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"X6zTIqN8gC0H","executionInfo":{"status":"ok","timestamp":1651761239797,"user_tz":-540,"elapsed":17,"user":{"displayName":"정환희","userId":"10718546972386594771"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["fit() 메서드로 40번의 훈련을 한다.   \n","이때 validation_data 파라미터로 검증세트를 튜플로 넘겨줄 수 있다.   \n","fit() 메서드는 훈련세트와 검증세트에서 측정한 값들을 History 클래스 객체에 담아 반환한다."],"metadata":{"id":"XZX9cqzVr8i2"}},{"cell_type":"code","source":["history = model.fit(train_data, train_target_encoded, epochs=40, validation_data=(val_data, val_target_encoded))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bGeDlNw0pFMI","executionInfo":{"status":"ok","timestamp":1651761962688,"user_tz":-540,"elapsed":172384,"user":{"displayName":"정환희","userId":"10718546972386594771"}},"outputId":"d927c8e8-d996-4cfc-dd7f-3c982db48097"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Train on 48000 samples, validate on 12000 samples\n","Epoch 1/40\n","48000/48000 [==============================] - 5s 106us/sample - loss: 1.3841 - accuracy: 0.6487 - val_loss: 0.9529 - val_accuracy: 0.7329\n","Epoch 2/40\n","48000/48000 [==============================] - 5s 97us/sample - loss: 0.8381 - accuracy: 0.7416 - val_loss: 0.7477 - val_accuracy: 0.7602\n","Epoch 3/40\n","48000/48000 [==============================] - 4s 93us/sample - loss: 0.7095 - accuracy: 0.7642 - val_loss: 0.6609 - val_accuracy: 0.7777\n","Epoch 4/40\n","48000/48000 [==============================] - 4s 91us/sample - loss: 0.6449 - accuracy: 0.7804 - val_loss: 0.6120 - val_accuracy: 0.7917\n","Epoch 5/40\n","48000/48000 [==============================] - 5s 94us/sample - loss: 0.6028 - accuracy: 0.7945 - val_loss: 0.5732 - val_accuracy: 0.8050\n","Epoch 6/40\n","48000/48000 [==============================] - 4s 87us/sample - loss: 0.5722 - accuracy: 0.8036 - val_loss: 0.5473 - val_accuracy: 0.8121\n","Epoch 7/40\n","48000/48000 [==============================] - 4s 88us/sample - loss: 0.5495 - accuracy: 0.8106 - val_loss: 0.5274 - val_accuracy: 0.8167\n","Epoch 8/40\n","48000/48000 [==============================] - 4s 92us/sample - loss: 0.5314 - accuracy: 0.8174 - val_loss: 0.5109 - val_accuracy: 0.8230\n","Epoch 9/40\n","48000/48000 [==============================] - 4s 86us/sample - loss: 0.5168 - accuracy: 0.8204 - val_loss: 0.4987 - val_accuracy: 0.8257\n","Epoch 10/40\n","48000/48000 [==============================] - 5s 95us/sample - loss: 0.5049 - accuracy: 0.8254 - val_loss: 0.4873 - val_accuracy: 0.8303\n","Epoch 11/40\n","48000/48000 [==============================] - 4s 91us/sample - loss: 0.4944 - accuracy: 0.8283 - val_loss: 0.4800 - val_accuracy: 0.8323\n","Epoch 12/40\n","48000/48000 [==============================] - 5s 95us/sample - loss: 0.4860 - accuracy: 0.8313 - val_loss: 0.4709 - val_accuracy: 0.8355\n","Epoch 13/40\n","48000/48000 [==============================] - 4s 82us/sample - loss: 0.4783 - accuracy: 0.8336 - val_loss: 0.4635 - val_accuracy: 0.8362\n","Epoch 14/40\n","48000/48000 [==============================] - 4s 93us/sample - loss: 0.4713 - accuracy: 0.8356 - val_loss: 0.4576 - val_accuracy: 0.8375\n","Epoch 15/40\n","48000/48000 [==============================] - 4s 89us/sample - loss: 0.4651 - accuracy: 0.8364 - val_loss: 0.4519 - val_accuracy: 0.8388\n","Epoch 16/40\n","48000/48000 [==============================] - 4s 91us/sample - loss: 0.4595 - accuracy: 0.8385 - val_loss: 0.4474 - val_accuracy: 0.8419\n","Epoch 17/40\n","48000/48000 [==============================] - 4s 84us/sample - loss: 0.4545 - accuracy: 0.8409 - val_loss: 0.4411 - val_accuracy: 0.8446\n","Epoch 18/40\n","48000/48000 [==============================] - 5s 99us/sample - loss: 0.4496 - accuracy: 0.8423 - val_loss: 0.4372 - val_accuracy: 0.8465\n","Epoch 19/40\n","48000/48000 [==============================] - 4s 92us/sample - loss: 0.4452 - accuracy: 0.8441 - val_loss: 0.4326 - val_accuracy: 0.8479\n","Epoch 20/40\n","48000/48000 [==============================] - 5s 94us/sample - loss: 0.4409 - accuracy: 0.8445 - val_loss: 0.4295 - val_accuracy: 0.8498\n","Epoch 21/40\n","48000/48000 [==============================] - 4s 84us/sample - loss: 0.4371 - accuracy: 0.8463 - val_loss: 0.4260 - val_accuracy: 0.8489\n","Epoch 22/40\n","48000/48000 [==============================] - 4s 82us/sample - loss: 0.4333 - accuracy: 0.8470 - val_loss: 0.4248 - val_accuracy: 0.8512\n","Epoch 23/40\n","48000/48000 [==============================] - 4s 86us/sample - loss: 0.4301 - accuracy: 0.8478 - val_loss: 0.4199 - val_accuracy: 0.8540\n","Epoch 24/40\n","48000/48000 [==============================] - 4s 92us/sample - loss: 0.4267 - accuracy: 0.8500 - val_loss: 0.4190 - val_accuracy: 0.8530\n","Epoch 25/40\n","48000/48000 [==============================] - 4s 86us/sample - loss: 0.4238 - accuracy: 0.8507 - val_loss: 0.4149 - val_accuracy: 0.8534\n","Epoch 26/40\n","48000/48000 [==============================] - 4s 91us/sample - loss: 0.4209 - accuracy: 0.8513 - val_loss: 0.4116 - val_accuracy: 0.8546\n","Epoch 27/40\n","48000/48000 [==============================] - 4s 86us/sample - loss: 0.4179 - accuracy: 0.8524 - val_loss: 0.4096 - val_accuracy: 0.8569\n","Epoch 28/40\n","48000/48000 [==============================] - 4s 89us/sample - loss: 0.4151 - accuracy: 0.8536 - val_loss: 0.4068 - val_accuracy: 0.8572\n","Epoch 29/40\n","48000/48000 [==============================] - 4s 87us/sample - loss: 0.4125 - accuracy: 0.8540 - val_loss: 0.4070 - val_accuracy: 0.8562\n","Epoch 30/40\n","48000/48000 [==============================] - 4s 85us/sample - loss: 0.4099 - accuracy: 0.8550 - val_loss: 0.4035 - val_accuracy: 0.8585\n","Epoch 31/40\n","48000/48000 [==============================] - 4s 85us/sample - loss: 0.4078 - accuracy: 0.8556 - val_loss: 0.4019 - val_accuracy: 0.8586\n","Epoch 32/40\n","48000/48000 [==============================] - 4s 92us/sample - loss: 0.4055 - accuracy: 0.8572 - val_loss: 0.4006 - val_accuracy: 0.8584\n","Epoch 33/40\n","48000/48000 [==============================] - 4s 85us/sample - loss: 0.4032 - accuracy: 0.8576 - val_loss: 0.3976 - val_accuracy: 0.8598\n","Epoch 34/40\n","48000/48000 [==============================] - 4s 87us/sample - loss: 0.4012 - accuracy: 0.8576 - val_loss: 0.3984 - val_accuracy: 0.8597\n","Epoch 35/40\n","48000/48000 [==============================] - 4s 93us/sample - loss: 0.3989 - accuracy: 0.8583 - val_loss: 0.3953 - val_accuracy: 0.8626\n","Epoch 36/40\n","48000/48000 [==============================] - 4s 84us/sample - loss: 0.3971 - accuracy: 0.8596 - val_loss: 0.3929 - val_accuracy: 0.8622\n","Epoch 37/40\n","48000/48000 [==============================] - 4s 87us/sample - loss: 0.3951 - accuracy: 0.8596 - val_loss: 0.3920 - val_accuracy: 0.8623\n","Epoch 38/40\n","48000/48000 [==============================] - 4s 90us/sample - loss: 0.3934 - accuracy: 0.8606 - val_loss: 0.3904 - val_accuracy: 0.8622\n","Epoch 39/40\n","48000/48000 [==============================] - 4s 92us/sample - loss: 0.3912 - accuracy: 0.8615 - val_loss: 0.3892 - val_accuracy: 0.8622\n","Epoch 40/40\n","48000/48000 [==============================] - 4s 83us/sample - loss: 0.3895 - accuracy: 0.8618 - val_loss: 0.3883 - val_accuracy: 0.8639\n"]}]},{"cell_type":"code","source":["print(history.history.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tmH-yghypVZT","executionInfo":{"status":"ok","timestamp":1651762097737,"user_tz":-540,"elapsed":15,"user":{"displayName":"정환희","userId":"10718546972386594771"}},"outputId":"cc8b6d31-d166-47f5-9cca-f0173bf71238"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"A7I-Mx1msWqj"},"execution_count":null,"outputs":[]}]}